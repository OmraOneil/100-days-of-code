{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "name": "Copie de perasVsManzanas.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmraOneil/100-days-of-code/blob/master/Copie_de_perasVsManzanas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FASGgV7IjdE"
      },
      "source": [
        "# Comparando peras con manzanas: una introducción al Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjIZhL1NIjdL"
      },
      "source": [
        "<table><tr>\n",
        "    <td><img src=\"https://albarji-labs-materials.s3-eu-west-1.amazonaws.com/pera.png\" width=500px></td>\n",
        "    <td><img src=\"https://albarji-labs-materials.s3-eu-west-1.amazonaws.com/manzana.png\" width=500px></td>\n",
        "</tr></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVYKwZ71IjdN"
      },
      "source": [
        "En este notebook vamos a experimentar un poco con las redes neuronales profundas (Deep Learning) para resolver una tarea divertida: ¡vamos a construir una IA que distinga fotos de **peras** y de **manzanas**!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeZu8_oKQYHN"
      },
      "source": [
        "Si nunca has usado un notebook de Google Colaboratory verás que es muy sencillo: avanza leyendo el texto y cuando encuentres una sección con código puedes ejecutarla haciendo click en el icono del triángulo que aparece cuando colocas el cursos del ratón sobre el código. También puedes desplazarte por el notebook con las flechas direccionales y ejecutar una sección de código pulsando Mayúsculas + Enter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1TNgvx-PGXY"
      },
      "source": [
        "## Preparando el entorno"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmAigYpKPJPY"
      },
      "source": [
        "Para poder entrenar una red neuronal en un tiempo razonable es fundamental contar con una GPU (Graphics Processing Unit). Este tipo de hardware está especialmente diseñado para realizar operaciones de red neuronal de forma muy eficiente, ahorrando así tiempos de cálculo y costes. Conectar una GPU a la instancia de Google en la que corre este notebook es muy sencillo:\r\n",
        "\r\n",
        "1. En la barra de menús arriba a la izquierda, haz click en la opción \"Entorno de ejecución\".\r\n",
        "2. En el desplegable, selecciona \"Cambiar tipo de entorno de ejecución\".\r\n",
        "3. En la venta que aparece, en el desplegable \"Acelerador por hardware\" selecciona \"GPU\".\r\n",
        "\r\n",
        "¡Listo! Podemos comprobar la GPU que se nos ha asignado ejecutando el siguiente comando."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6Mny9XqQLN0"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIzViEhxIjdU"
      },
      "source": [
        "## Adquisición de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVyrvLulIjdU"
      },
      "source": [
        "Vamos a utilizar un conjunto de datos de fotos de frutas disponible en [Kaggle](https://www.kaggle.com/moltean/fruits). Para poder descargar estos datos normalmente sería necesario crearse una cuenta en Kaggle y obtener unas credenciales; además necesitaríamos procesar estos datos para quedarnos solo con las fotos de peras y manzanas de entre todas las fotos de frutas disponibles. Para facilitar este ejercicio ya disponemos de una versión lista para usar de estos datos, que podemos descargar usando el siguiente comando."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtMiZ0-rOPWy"
      },
      "source": [
        "!wget https://albarji-labs-materials.s3-eu-west-1.amazonaws.com/perasVSmanzanas.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOOPzKJERolH"
      },
      "source": [
        "Ahora vamos a descomprimir los datos que hemos descargado, usando el siguiente comando"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aL0CWNpOaNG"
      },
      "source": [
        "!tar -xvzf perasVSmanzanas.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHr2RQ8YRuqY"
      },
      "source": [
        "Podemos comprobar que los datos se han descargado completamente seleccionando el icono de la carpeta que aparece a la izquierda, lo cual nos mostrará en el lateral un explorador de ficheros. Deberían poder verse una carpeta `train_data` con los datos que usaremos para que la red neuronal aprenda, y otra carpeta `test_data` con los datos que emplearemos para comprobar si la red funciona. Si no ves estas carpetas, haz click en el icono de `Actualizar`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjjZNfRyIjdZ"
      },
      "source": [
        "Vamos a visualizar las imágenes de peras y manzanas que tenemos. Para ello necesitamos instalar el paquete ipyplot de python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfediRDdEV67"
      },
      "source": [
        "!pip install ipyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeWfsWedEj-x"
      },
      "source": [
        "El siguiente código nos mostrará una pequeña interfaz donde visualizar una muestra de las imágenes que trabajaremos. Puedes cambiar entre peras y manzanas usando las pestañas que se muestran arriba a la izquierda."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Apq4xcJ7Ijdb",
        "scrolled": false
      },
      "source": [
        "from glob import glob\n",
        "import ipyplot\n",
        "import numpy as np\n",
        "\n",
        "all_images = glob(\"./train_data/*/*.jpg\")  # Get all image paths\n",
        "np.random.shuffle(all_images)  # Randomize to show different images each run\n",
        "all_labels = [f.split(\"/\")[-2] for f in all_images]  # Extract class names from path\n",
        "\n",
        "ipyplot.plot_class_tabs(all_images, all_labels, max_imgs_per_tab=60, img_width=100, force_b64=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn7sGkHdE4Vi"
      },
      "source": [
        "Estas fotos se han obtenido eliminando el fondo de la imagen con un proceso automático, por lo que puede que en en algunos casos se aprecien bordes algo mal definidos. Igualmente, podemos trabajar con este conjunto de imágenes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fz8UESjIjdd"
      },
      "source": [
        "## Cargando las imágenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUbF7Hs6Ijdd"
      },
      "source": [
        "Para que la red neuronal pueda aprender de las imágenes, primero necesitamos construir un `Dataset` en base a ellas. Un `Dataset` es un objeto que se encarga de ir cargando las imágenes de disco cuando las necesitamos, evitando así tenerlas todas en memoria al mismo tiempo. Además nos facilita algunas tareas de procesado de las imágenes.\n",
        "\n",
        "Podemos crear un  `Dataset` con todas las imágenes de la carpeta de entrenamiento de la siguiente manera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-2fsuGBIjde"
      },
      "source": [
        "from keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "image_size = 100\n",
        "batch_size = 64\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    \"./train_data\", \n",
        "    image_size = (image_size, image_size),\n",
        "    batch_size = batch_size, \n",
        "    label_mode = 'binary'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0oCyL-dIjdf"
      },
      "source": [
        "Los parámetros con los que se configura el dataset son los siguientes:\n",
        "\n",
        "* El **directorio** donde encontrar las imágenes.\n",
        "* El **tamaño de imagen** al que se redimensionarán las imágenes al cargarlas en memoria, en este caso 100x100 píxeles.\n",
        "* EL **tamaño de los batches** de imágenes que se generarán. La red neuronal irá procesando imágenes en grupos de este tamaño, evitando así mantenerlas todas en memoria al mismo tiempo.\n",
        "* El **modo de etiquetado**, esto es, qué clase de problema de clasificación estamos resolviendo en este caso. Aquí queremos tomar una decisión binaria (peras VS manzanas), por lo que elegimos el modo binario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcy4v-L3Ijdf"
      },
      "source": [
        "Un `Dataset` funciona como un generador de python, lo que significa que podemos iterar sobre él para ir obteniendo cada uno de los batches o grupos de imágenes. Por ejemplo, con el código siguiente podemos observar el primer batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsK3OQ-9Ijdg"
      },
      "source": [
        "for X_batch, y_batch in train_dataset:\n",
        "    print(f\"Shape of input batch: {X_batch.shape}\")\n",
        "    print(f\"Shape of output batch: {y_batch.shape}\")\n",
        "    print(f\"Input batch:\\n{X_batch}\")\n",
        "    print(f\"Output batch:\\n{y_batch}\")\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfDy1zzgIjdh"
      },
      "source": [
        "Podemos ver cómo el generador produce un tensor de entrada conteniendo los datos de un batch de imágenes, así como tensor de salida en el que manzanas y peras se han codificado con las etiquetas 0 y 1. Las imágenes se representan como una serie de píxeles en el rango `[0, 255]`, representando el valor de intensidad de cada píxel.\r\n",
        "\r\n",
        "Vamos ahora a crear otro `Dataset` con los datos de test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UutxVgWPIjdh"
      },
      "source": [
        "test_dataset = image_dataset_from_directory(\n",
        "    \"./test_data\", \n",
        "    batch_size = batch_size, \n",
        "    image_size = (image_size, image_size),\n",
        "    label_mode = 'binary'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKwiEgJzIJJ1"
      },
      "source": [
        "## Construyendo nuestra primera red neuronal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HME_SV_FIjdi"
      },
      "source": [
        "Ahora que tenemos nuestros datos, ¡vamos a entrenar una red neuronal! El siguiente código diseña la red usando la librería de Deep Learning [Keras](https://keras.io/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6HMQhAWIjdi"
      },
      "source": [
        "# Importamos los elementos de Keras que necesitamos\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.layers.experimental.preprocessing import Rescaling\n",
        "\n",
        "# Inicializamos la red neuronal como de tipo Secuencial: cada elemento que añadamos a la red se conecta al declarado anteriormente\n",
        "model = Sequential()\n",
        "# Añadimos una capa que normaliza los valores de los píxeles, de [0, 255] a [0, 1]\n",
        "model.add(Rescaling(scale=1./255, input_shape=(image_size, image_size, 3)))\n",
        "# Añadimos una capa convolucional para que la red aprenda a detectar bordes\n",
        "model.add(Convolution2D(32, 3, activation='relu'))\n",
        "# Añadimos una capa de pooling para focalizar el detector anterior\n",
        "model.add(MaxPooling2D(2))\n",
        "# Aplanamos las imágenes resultado\n",
        "model.add(Flatten())\n",
        "# Añadimos una unidad final de salida, que nos dará un valor entre 0 y 1 para indicar si la imagen es pera o manzana\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilamos la red neuronal: en este paso Keras analiza nuestro diseño y genera código CUDA para que la red pueda entrenarse\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=[\"accuracy\"])\n",
        "# Mostramos un resumen de la red construída\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V4DGLUvIjdi"
      },
      "source": [
        "Una vez diseñada la red, podemos hacer que aprenda usando el `Dataset` de entrenamiento. Vamos a realizar 1 época, esto es, la red neuronal aprenderá observando las imágenes de entrenamiento una sola vez."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0416fHYIjdj"
      },
      "source": [
        "model.fit(train_dataset, epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY1lMYJHIjdj"
      },
      "source": [
        "Una vez entrenada, podemos medir el acierto de la red sobre los datos de test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozIbwO_TIjdk"
      },
      "source": [
        "loss, acc = model.evaluate(test_dataset)\n",
        "print(f\"Loss {loss:.3}, accuracy {acc:.1%}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LtIkFAlIjdk"
      },
      "source": [
        "¡Conseguimos más de un 80% de acierto! No está mal, ¡pero podemos hacerlo mejor!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Figw7oMyIjdl"
      },
      "source": [
        "## Creando una red más profunda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41PQ2B_vIRYT"
      },
      "source": [
        "Vamos a crear una red más profunda, usando más capas de Convolución y MaxPooling, de manera que así la red neuronal pueda identificar elementos más complejos en la imagen. Asímismo, vamos a añadir una capa Densa tras el aplanado para que las características visuales detectadas puedan procesarse de forma más avanzada. También vamos a añadir una capa de Dropout para robustecer la red neuronal y que sea más precisa. Finalmente, enseñaremos cada imagen 10 veces a la red neuronal para mejorar su aprendizaje."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpPFJGN4Ijdm"
      },
      "source": [
        "# Importamos algunos objetos más de Keras\n",
        "from keras.layers.core import Dropout\n",
        "\n",
        "# Initializamos la red\n",
        "model = Sequential()\n",
        "# Añadimos una capa que normaliza los valores de los píxeles, de [0, 255] a [0, 1]\n",
        "model.add(Rescaling(scale=1./255, input_shape=(image_size, image_size, 3)))\n",
        "# Añadimos una capa convolucional para que la red aprenda a detectar bordes\n",
        "model.add(Convolution2D(32, 3, activation='relu'))\n",
        "# Añadimos una capa de pooling para focalizar el detector anterior\n",
        "model.add(MaxPooling2D(2))\n",
        "# Añadimos una segunda capa convolucional para que la red aprenda a detectar elementos más complejos, como figuras geométricas\n",
        "model.add(Convolution2D(64, 3, activation='relu'))\n",
        "# Añadimos una capa de pooling para focalizar el detector anterior\n",
        "model.add(MaxPooling2D(2))\n",
        "# Añadimos una tercera capa convolucional para que la red aprenda a detectar elementos aún más complejos, como patrones formados por figuras geométricas\n",
        "model.add(Convolution2D(128, 3, activation='relu'))\n",
        "# Añadimos una capa de pooling para focalizar el detector anterior\n",
        "model.add(MaxPooling2D(2))\n",
        "# Aplanamos las imágenes resultado\n",
        "model.add(Flatten())\n",
        "# Añadimos una capa densa para procesar las características visuales detectadas por la capa anterior\n",
        "model.add(Dense(64, activation='relu'))\n",
        "# Añadimos Dropout al 50% para que la red se acostumbre a imágenes que puedan contener fallos\n",
        "model.add(Dropout(0.5))\n",
        "# Añadimos una unidad final de salida, que nos dará un valor entre 0 y 1 para indicar si la imagen es pera o manzana\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilamos la red neuronal\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
        "# Mostramos un resumen de la red construída\n",
        "model.summary()\n",
        "\n",
        "# Hacemos que la red aprenda\n",
        "model.fit(train_dataset, epochs=10)\n",
        "\n",
        "# Calculamos el acierto sobre los datos de test\n",
        "loss, acc = model.evaluate(test_dataset)\n",
        "print(f\"Loss {loss:.3}, accuracy {acc:.1%}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwmYyyejJodR"
      },
      "source": [
        "¡Una red más profunda produce resultados mucho mejores!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBq44oW4Ijdm"
      },
      "source": [
        "## Transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egwU9lXqIjdm"
      },
      "source": [
        "Podemos mejorar aún más la red anterior si en lugar de diseñarla nosotros desde 0 partimos de un diseño de red ya existente. La librería Keras incluye varios de estos diseños en su módulo [Keras Applications](https://keras.io/api/applications/); en esta ocasión vamos a usar la red VGG16."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgT5gG9iIjdn"
      },
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "vgg16_model = VGG16(include_top=False, input_shape=(image_size, image_size, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2oY6lmCKB9p"
      },
      "source": [
        "Podemos ver cómo está construída esta red. ¡Es mucho más profunda que las que hemos hecho antes!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOgN3keBKJWh"
      },
      "source": [
        "vgg16_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04iiDOwAIjdo"
      },
      "source": [
        "Por defecto todas las redes de Keras Applications vienen precargadas con los parámetros con los que fueron entrenadas: [el dataset ImageNet](http://www.image-net.org/). Este dataset está conformado por multitud de imágenes naturales, lo que ayuda a que la red ya sea capaz de reconocer bastantes elementos gráficos y objetos. Para preservar ese conocimiento en la red neuronal, vamos a marcar que durante el proceso de aprendizaje que haremos a continuación estos parámetros no puedan variar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi-Zp1-OIjdp"
      },
      "source": [
        "vgg16_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBSeQKwAIjdp"
      },
      "source": [
        "Ahora vamos a construir nuestra red neuronal propia, usando la VGG16 pre-entrenada como parte de ella. Empezamos construyendo la red con una capa que normalice las imágenes al formato esperado por la VGG16, después añadimos la propia VGG16, y continuación aplanamos y repetimos el patrón de las redes que hemos diseñado antes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC32MHj-Ijdq"
      },
      "source": [
        "# Importamos algunos objetos más de Keras\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.layers import Lambda\n",
        "\n",
        "# Initializamos la red\n",
        "model = Sequential()\n",
        "# Añadimos una capa que realice la normalización de imágenes que requiere VGG16\n",
        "model.add(Lambda(preprocess_input, input_shape=(image_size, image_size, 3)))\n",
        "# Añadimos la VGG16\n",
        "model.add(vgg16_model)\n",
        "# Aplanamos las imágenes resultado\n",
        "model.add(Flatten())\n",
        "# Añadimos una capa densa para procesar las características visuales detectadas por la capa anterior\n",
        "model.add(Dense(64, activation='relu'))\n",
        "# Añadimos Dropout al 50% para que la red se acostumbre a imágenes que puedan contener fallos\n",
        "model.add(Dropout(0.5))\n",
        "# Añadimos una unidad final de salida, que nos dará un valor entre 0 y 1 para indicar si la imagen es pera o manzana\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilamos la red neuronal\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
        "# Mostramos un resumen de la red construída\n",
        "model.summary()\n",
        "\n",
        "# Hacemos que la red aprenda\n",
        "model.fit(train_dataset, epochs=10)\n",
        "\n",
        "# Calculamos el acierto sobre los datos de test\n",
        "loss, acc = model.evaluate(test_dataset)\n",
        "print(f\"Loss {loss:.3}, accuracy {acc:.1%}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVTt2xzWLjYt"
      },
      "source": [
        "¡Reutilizando una red pre-entrenada hemos conseguido un nivel de acierto casi perfecto!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tph3voM_TJwL"
      },
      "source": [
        "## Probando con otras imágenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LJmvgaMLrkp"
      },
      "source": [
        "¿No te fías de que la red neuronal que hemos hecho funcione? ¡Pruébalo con la foto que quieras! A continuación definimos la función `download_image` que dada la URL de una imagen la guarda como una variable en python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJfgGCb7P_p0"
      },
      "source": [
        "from io import BytesIO\r\n",
        "import numpy as np\r\n",
        "import requests\r\n",
        "\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "def download_image(image_url):\r\n",
        "    return Image.open(requests.get(image_url, stream=True).raw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7RtVYkETXib"
      },
      "source": [
        "Aquí tienes algunas URL de imágenes que puedes usar:\r\n",
        "\r\n",
        "Manzanas:\r\n",
        "\r\n",
        "* https://upload.wikimedia.org/wikipedia/commons/2/25/Alice_%28apple%29.jpg\r\n",
        "* https://upload.wikimedia.org/wikipedia/commons/d/d2/Malus-Boskoop_organic.jpg\r\n",
        "\r\n",
        "Peras\r\n",
        "\r\n",
        "* https://upload.wikimedia.org/wikipedia/commons/2/2d/PearPhoto.jpg\r\n",
        "* https://upload.wikimedia.org/wikipedia/commons/thumb/5/5d/Pear_DS.jpg/1920px-Pear_DS.jpg\r\n",
        "* https://upload.wikimedia.org/wikipedia/commons/c/cf/Pears.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VHjswbaMM0g"
      },
      "source": [
        "Cambia la URL que aparece a continuación y ejecuta el código para descargar la imagen y mostrarla."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SERy5yoIQBu7"
      },
      "source": [
        "img = download_image(\"https://upload.wikimedia.org/wikipedia/commons/2/25/Alice_%28apple%29.jpg\")\r\n",
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVm4F5MhM-oL"
      },
      "source": [
        "Dado que la imagen que has elegido puede venir en cualquier formato y tamaño, vamos a definir la siguiente función para que normalice esa imagen y la convierta al formato adecuado para la red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdoFrXE0RTSD"
      },
      "source": [
        "import numpy as np\r\n",
        "from skimage.transform import resize\r\n",
        "\r\n",
        "def preprocess_image(img):\r\n",
        "    img = np.array(img.resize((100, 100)))\r\n",
        "    return np.expand_dims(img, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV0bqWp_NG9w"
      },
      "source": [
        "Con el siguiente código aplicamos la normalización sobre la imagen que hemos descargado, obteniendo así `img_ready`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-RKNz13RfQU"
      },
      "source": [
        "img_ready = preprocess_image(img)\r\n",
        "img_ready"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs8UIH1NNLdy"
      },
      "source": [
        "Ahora analizamos la imagen con la red neuronal para que nos dé una respuesta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEbrnQLiRifp"
      },
      "source": [
        "probability = model.predict(img_ready)\r\n",
        "probability"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MORrVtdZNRlw"
      },
      "source": [
        "¿Qué significa el valor `probability` que hemos obtenido? Es la confianza que tiene la red neuronal en que la imagen represente una pera o una manzana. Si el valor devuelto es cercano a `0`, la red está muy segura de que la imagen muestra una manzana, en cambio si el valor es cercano a `1` está convencida de que se trata de una pera. El siguiente código decide cortar esta probabilidad en el punto medio (`0.5`) y en base a eso enunciar si estamos ante una manzana o pera."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKnV1ZcySrK8"
      },
      "source": [
        "label = 1 if probability[0][0] > 0.5 else 0\r\n",
        "train_dataset.class_names[label]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "510-DzQBOAe2"
      },
      "source": [
        "## Cierre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRWN3SV0OCtz"
      },
      "source": [
        "Y... ¿esto es todo amigos? ¡No! El desafío que nos hemos propuesto es sencillo, pero aún así la red neuronal profunda que hemos construído es aún mejorable. Si le pasamos una fotografía de una fruta con mala iluminación o con otros elementos presentes que sean distractores, probablemente la red neuronal falle. Existen muchas técnicas que podemos usar para robustecer nuestra red ante estos problemas, y mucho más que aprender en el mundo de las redes neuronales profundas. ¡Esto es solo el comienzo! :)"
      ]
    }
  ]
}